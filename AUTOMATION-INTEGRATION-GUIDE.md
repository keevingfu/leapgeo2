# è‡ªåŠ¨åŒ–å¼€å‘èµ„æºæ•´åˆæŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•ç»¼åˆåˆ©ç”¨å…¨å±€å’Œé¡¹ç›®çº§åˆ«çš„æ‰€æœ‰è‡ªåŠ¨åŒ–å¼€å‘èƒ½åŠ›ï¼Œå®ç°é«˜æ•ˆçš„ AI é©±åŠ¨å¼€å‘æµç¨‹ã€‚

---

## ğŸ“¦ å¯ç”¨èµ„æºæ¸…å•

### ğŸŒ å…¨å±€èµ„æºï¼ˆ/Users/cavin/CLAUDE.mdï¼‰

#### 1. Context Engineering Framework
**ä½ç½®**: `/Users/cavin/Context-Engineering-Intro`

**æ ¸å¿ƒå‘½ä»¤**:
- `/generate-prp [feature-file]` - ç”Ÿæˆäº§å“éœ€æ±‚æç¤ºï¼ˆPRPï¼‰
- `/execute-prp [prp-file]` - æ‰§è¡Œ PRP å®ç°åŠŸèƒ½

**å·¥ä½œæµ**:
```
åˆ›å»º INITIAL.md â†’ ç”Ÿæˆ PRP â†’ æ‰§è¡Œå®ç° â†’ è‡ªåŠ¨éªŒè¯
```

**é€‚ç”¨åœºæ™¯**:
- âœ… å¤æ‚åŠŸèƒ½æ¨¡å—å¼€å‘ï¼ˆéœ€è¦å¤§é‡ä¸Šä¸‹æ–‡ï¼‰
- âœ… è·¨æ–‡ä»¶é‡æ„
- âœ… API é›†æˆ
- âœ… æ•°æ®åº“è¿ç§»

---

#### 2. SuperClaude å‘½ä»¤ç³»ç»Ÿï¼ˆ17ä¸ªå‘½ä»¤ï¼‰

**ä½ç½®**: `/Users/cavin/.claude/commands/sc/`

| å‘½ä»¤ | åŠŸèƒ½ | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| `/sc:analyze` | ä»£ç è´¨é‡åˆ†æ | æ–‡ä»¶è·¯å¾„/ç›®å½• | é—®é¢˜æŠ¥å‘Š + æ”¹è¿›å»ºè®® |
| `/sc:build` | æ„å»ºå’Œæ‰“åŒ… | é¡¹ç›®é…ç½® | æ„å»ºäº§ç‰© + é”™è¯¯å¤„ç† |
| `/sc:cleanup` | æ¸…ç†æ­»ä»£ç  | é¡¹ç›®è·¯å¾„ | æ¸…ç†æŠ¥å‘Š + ä¼˜åŒ–å»ºè®® |
| `/sc:design` | æ¶æ„è®¾è®¡ | åŠŸèƒ½éœ€æ±‚ | æ¶æ„å›¾ + API è®¾è®¡ |
| `/sc:document` | ç”Ÿæˆæ–‡æ¡£ | ä»£ç /API | Markdown æ–‡æ¡£ |
| `/sc:estimate` | å·¥ä½œé‡ä¼°ç®— | ä»»åŠ¡åˆ—è¡¨ | æ—¶é—´ä¼°ç®— + èµ„æºåˆ†é… |
| `/sc:explain` | ä»£ç è§£é‡Š | ä»£ç ç‰‡æ®µ | è¯¦ç»†è¯´æ˜ + ç¤ºä¾‹ |
| `/sc:git` | æ™ºèƒ½ Git æ“ä½œ | å˜æ›´å†…å®¹ | è‡ªåŠ¨ commit + PR |
| `/sc:implement` | åŠŸèƒ½å®ç° | éœ€æ±‚æè¿° | å®Œæ•´ä»£ç  + æµ‹è¯• |
| `/sc:improve` | ä»£ç æ”¹è¿› | ä»£ç æ–‡ä»¶ | ä¼˜åŒ–åçš„ä»£ç  |
| `/sc:index` | é¡¹ç›®ç´¢å¼• | é¡¹ç›®æ ¹ç›®å½• | çŸ¥è¯†åº“æ–‡æ¡£ |
| `/sc:load` | åŠ è½½ä¸Šä¸‹æ–‡ | é¡¹ç›®è·¯å¾„ | ä¸Šä¸‹æ–‡æ‘˜è¦ |
| `/sc:spawn` | ä»»åŠ¡åˆ†è§£ | å¤æ‚ä»»åŠ¡ | å­ä»»åŠ¡åˆ—è¡¨ + æ‰§è¡Œè®¡åˆ’ |
| `/sc:task` | ä»»åŠ¡æ‰§è¡Œ | ä»»åŠ¡æè¿° | æ‰§è¡Œç»“æœ + æŒä¹…åŒ–è®°å½• |
| `/sc:test` | æµ‹è¯•æ‰§è¡Œ | æµ‹è¯•èŒƒå›´ | æµ‹è¯•æŠ¥å‘Š + è¦†ç›–ç‡ |
| `/sc:troubleshoot` | é—®é¢˜è¯Šæ–­ | é”™è¯¯ä¿¡æ¯ | æ ¹å› åˆ†æ + è§£å†³æ–¹æ¡ˆ |
| `/sc:workflow` | å·¥ä½œæµç”Ÿæˆ | PRD æ–‡æ¡£ | å®æ–½è®¡åˆ’ + æ£€æŸ¥ç‚¹ |

**ä½¿ç”¨åŸåˆ™**:
- ğŸ¯ `/sc:load` åœ¨æ¯æ¬¡ä¼šè¯å¼€å§‹æ—¶ä½¿ç”¨ï¼ˆåŠ è½½é¡¹ç›®ä¸Šä¸‹æ–‡ï¼‰
- ğŸ”„ `/sc:analyze` â†’ `/sc:improve` å½¢æˆä»£ç è´¨é‡æ”¹è¿›å¾ªç¯
- ğŸ“ `/sc:design` â†’ `/sc:implement` â†’ `/sc:test` å½¢æˆå®Œæ•´å¼€å‘æµç¨‹
- ğŸš€ `/sc:git` åœ¨åŠŸèƒ½å®Œæˆåè‡ªåŠ¨æäº¤

---

#### 3. BMAD è§’è‰²ä»£ç†ï¼ˆ10ä¸ªä¸“ä¸šè§’è‰²ï¼‰

**ä½ç½®**: Context Engineering BMAD æˆ– SuperClaude

| è§’è‰² | å‘½ä»¤ | ä¸“é•¿ | è¾“å‡ºç‰© |
|------|------|------|--------|
| ä¸šåŠ¡åˆ†æå¸ˆ | `/analyst` | å¸‚åœºç ”ç©¶ã€éœ€æ±‚åˆ†æ | ç«å“åˆ†ææŠ¥å‘Šã€ç”¨æˆ·ç”»åƒ |
| æ¶æ„å¸ˆ | `/architect` | ç³»ç»Ÿè®¾è®¡ã€æŠ€æœ¯é€‰å‹ | æ¶æ„å›¾ã€æŠ€æœ¯æ–¹æ¡ˆ |
| é¡¹ç›®ç»ç† | `/pm` | è§„åˆ’ã€è¿›åº¦ç®¡ç† | PRDã€é¡¹ç›®è®¡åˆ’ |
| äº§å“è´Ÿè´£äºº | `/po` | äº§å“æ„¿æ™¯ã€ä¼˜å…ˆçº§ | äº§å“è·¯çº¿å›¾ã€Story Map |
| å¼€å‘å·¥ç¨‹å¸ˆ | `/dev` | ä»£ç å®ç° | åŠŸèƒ½ä»£ç ã€å•å…ƒæµ‹è¯• |
| è´¨é‡ä¿è¯ | `/qa` | æµ‹è¯•ã€è´¨é‡æŠŠæ§ | æµ‹è¯•ç”¨ä¾‹ã€Bug æŠ¥å‘Š |
| Scrum Master | `/sm` | æ•æ·æµç¨‹ã€å›¢é˜Ÿåä½œ | Sprint è®¡åˆ’ã€å›é¡¾ |
| UX ä¸“å®¶ | `/ux-expert` | ç”¨æˆ·ä½“éªŒã€äº¤äº’è®¾è®¡ | åŸå‹ã€ç”¨æˆ·æµç¨‹å›¾ |
| BMAD ç¼–æ’å™¨ | `/bmad-orchestrator` | å¤šè§’è‰²åè°ƒ | ç»¼åˆæ–¹æ¡ˆ |
| BMAD å¤§å¸ˆ | `/bmad-master` | å¤æ‚ä»»åŠ¡åˆ†è§£ | å®Œæ•´è§£å†³æ–¹æ¡ˆ |

**åä½œæ¨¡å¼**:
```
/analyst â†’ /architect â†’ /pm â†’ /dev â†’ /qa â†’ /sm
   â†“          â†“          â†“       â†“       â†“      â†“
 è°ƒç ”æŠ¥å‘Š   æ¶æ„è®¾è®¡   PRD    ä»£ç     æµ‹è¯•   äº¤ä»˜
```

---

#### 4. MCP æœåŠ¡å™¨ï¼ˆ20ä¸ªå·²é…ç½®ï¼‰

##### ğŸ—„ï¸ æ•°æ®å­˜å‚¨å±‚

| æœåŠ¡ | ç«¯å£ | ç”¨é€” | çŠ¶æ€ |
|------|------|------|------|
| **PostgreSQL** | 5437 | ä¸šåŠ¡æ•°æ®ï¼ˆProjects, Prompts, Citationsï¼‰ | âœ… æ ¸å¿ƒä¾èµ– |
| **Neo4j** | 7688 (Bolt), 7475 (HTTP) | çŸ¥è¯†å›¾è°±ï¼ˆBrand-Product-Featureï¼‰ | âœ… æ ¸å¿ƒä¾èµ– |
| **Redis** | 6382 | ç¼“å­˜ã€ä¼šè¯ã€ä»»åŠ¡é˜Ÿåˆ— | âœ… æ ¸å¿ƒä¾èµ– |
| **MongoDB** | 27018 | åŸå§‹å†…å®¹æ•°æ®ï¼ˆAI å“åº” JSONï¼‰ | âœ… å¯é€‰ |
| **SQLite Explorer** | - | å®‰å…¨çš„åªè¯» SQLite è®¿é—® | âœ… å·¥å…· |
| **Prisma** | - | ç°ä»£ ORMï¼ˆå¯æ›¿ä»£ SQLAlchemyï¼‰ | âš ï¸ æœªå¯ç”¨ |

**è¿æ¥ä¿¡æ¯**:
```bash
# PostgreSQL
postgresql://claude:claude_dev_2025@localhost:5437/claude_dev

# Neo4j
neo4j://localhost:7688 (user: neo4j, pass: claude_neo4j_2025)
Browser: http://localhost:7475

# Redis
redis://:claude_redis_2025@localhost:6382

# MongoDB
mongodb://claude:claude_mongo_2025@localhost:27018/claude_dev?authSource=admin
```

**Docker ç®¡ç†**:
```bash
# å¯åŠ¨æ‰€æœ‰æ•°æ®åº“
docker start postgres-claude-mcp neo4j-claude-mcp redis-claude-mcp mongodb-claude-mcp

# æ£€æŸ¥çŠ¶æ€
docker ps | grep claude-mcp

# æŸ¥çœ‹æ—¥å¿—
docker logs -f postgres-claude-mcp

# é‡å¯ç‰¹å®šæ•°æ®åº“
docker restart neo4j-claude-mcp
```

---

##### ğŸŒ Web è‡ªåŠ¨åŒ–å±‚

| æœåŠ¡ | åŠŸèƒ½ | åº”ç”¨åœºæ™¯ |
|------|------|----------|
| **Firecrawl** (è‡ªå»º) | Web æ•°æ®æŠ“å– | Citation è¿½è¸ªã€ç«å“ç›‘æ§ |
| **Puppeteer** | æµè§ˆå™¨è‡ªåŠ¨åŒ– | E2E æµ‹è¯•ã€å¹³å°å‘å¸ƒ |
| **Chrome DevTools** | å¼€å‘è€…å·¥å…·é›†æˆ | æ€§èƒ½åˆ†æã€ç½‘ç»œè°ƒè¯• |

**Firecrawl å¯åŠ¨**:
```bash
cd /Users/cavin/firecrawl
docker compose up -d

# ç®¡ç†ç•Œé¢
open http://localhost:3002/admin/@/queues

# æŸ¥çœ‹æ—¥å¿—
docker compose logs -f
```

**Puppeteer ç¤ºä¾‹**ï¼ˆGEO å¹³å°åº”ç”¨ï¼‰:
```javascript
// è‡ªåŠ¨åŒ– YouTube å†…å®¹å‘å¸ƒ
const { chromium } = require('playwright');

async function publishToYouTube(videoPath, metadata) {
  const browser = await chromium.launch({ headless: false });
  const page = await browser.newPage();

  await page.goto('https://studio.youtube.com');
  // ç™»å½•é€»è¾‘...
  await page.setInputFiles('input[type="file"]', videoPath);
  await page.fill('input[name="title"]', metadata.title);
  await page.fill('textarea[name="description"]', metadata.description);
  await page.click('button:has-text("Publish")');

  await browser.close();
}
```

---

##### ğŸ§  AI å¢å¼ºå±‚

| æœåŠ¡ | åŠŸèƒ½ | åº”ç”¨åœºæ™¯ |
|------|------|----------|
| **Sequential Thinking** | ç»“æ„åŒ–æ¨ç† | Prompt è¯„åˆ†ç®—æ³•ä¼˜åŒ–ã€Citation æ¨¡å¼è¯†åˆ« |
| **Memory** | æŒä¹…åŒ–è®°å¿† | è·¨é¡¹ç›®çŸ¥è¯†å…±äº«ã€æœ€ä½³å®è·µç§¯ç´¯ |

**Sequential Thinking ç¤ºä¾‹**:
```javascript
// åˆ†æé«˜ Citation Rate Prompt çš„å…±åŒç‰¹å¾
const analysis = await sequentialThinking.analyze({
  task: "è¯†åˆ« Citation Rate >35% çš„ Prompt å…±åŒæ¨¡å¼",
  data: {
    highPerformingPrompts: [
      { text: "best mattress for hot sleepers 2025", rate: 0.38 },
      { text: "cooling mattress reviews comparison", rate: 0.36 },
      // ...
    ]
  },
  steps: [
    "æå–å…³é”®è¯é¢‘ç‡",
    "åˆ†æå¥å¼ç»“æ„",
    "è¯†åˆ«ç”¨æˆ·æ„å›¾",
    "å¯¹æ¯”ä½è¡¨ç° Prompt",
    "ç”Ÿæˆä¼˜åŒ–å»ºè®®"
  ]
});

console.log(analysis.insights);
// Output:
// - åŒ…å«æ—¶é—´æ ‡è®°ï¼ˆ"2025"ï¼‰çš„ Prompt è¡¨ç°æ›´å¥½
// - å¯¹æ¯”ç±»å…³é”®è¯ï¼ˆ"vs", "comparison"ï¼‰æå‡ Citation Rate
// - å…·ä½“é—®é¢˜ï¼ˆ"for hot sleepers"ï¼‰æ¯”æ³›åŒ–æŸ¥è¯¢æ•ˆæœå¥½
```

**Memory ç¤ºä¾‹**:
```javascript
// ä¿å­˜æˆåŠŸç­–ç•¥
await memory.save({
  topic: "GEO Platform - High Citation Rate Strategies",
  context: {
    project: "SweetNight Mattress",
    strategy: "Focus on problem-solution Prompts with year markers",
    prompt_template: "best [product] for [problem] [year]",
    result: {
      before: { citationRate: 0.28, prompts: 120 },
      after: { citationRate: 0.35, prompts: 156 }
    }
  },
  tags: ["geo", "prompt-optimization", "citation-rate"]
});

// åœ¨æ–°é¡¹ç›®ä¸­æ£€ç´¢
const insights = await memory.recall("High Citation Rate Strategies", {
  filter: { tags: ["geo", "prompt-optimization"] }
});

console.log(`æ‰¾åˆ° ${insights.length} æ¡ç›¸å…³ç»éªŒ`);
```

---

##### ğŸ¨ UI ç”Ÿæˆå±‚

| æœåŠ¡ | åŠŸèƒ½ | åº”ç”¨åœºæ™¯ |
|------|------|----------|
| **Magic UI** | AI ç”Ÿæˆ React ç»„ä»¶ | å¿«é€ŸåŸå‹ã€Dashboard å¯è§†åŒ– |

**Magic UI ç¤ºä¾‹**:
```javascript
// å¿«é€Ÿç”Ÿæˆ Citation Tracking Dashboard
const component = await magicUI.generate({
  type: "dashboard",
  title: "AI Platform Citation Tracking",
  metrics: [
    { label: "ChatGPT", value: 45, color: "#10a37f" },
    { label: "Claude", value: 38, color: "#c17d5e" },
    { label: "Perplexity", value: 52, color: "#20808d" },
    { label: "Gemini", value: 29, color: "#4285f4" }
  ],
  charts: [
    { type: "line", data: "citationTrend", title: "Citation Trend" },
    { type: "radar", data: "platformComparison", title: "Platform Comparison" },
    { type: "bar", data: "topPrompts", title: "Top Prompts" }
  ],
  style: "tailwind",
  icons: "lucide-react"
});

// è¾“å‡º TypeScript + Tailwind CSS ç»„ä»¶ä»£ç 
console.log(component.code);
```

---

##### ğŸ”§ ç‰ˆæœ¬æ§åˆ¶ & DevOps

| æœåŠ¡ | åŠŸèƒ½ | åº”ç”¨åœºæ™¯ |
|------|------|----------|
| **GitHub MCP** | GitHub æ“ä½œ | Issue ç®¡ç†ã€PR åˆ›å»ºã€ä»£ç å®¡æŸ¥ |
| **GitLab MCP** | GitLab CI/CD | æµæ°´çº¿è§¦å‘ã€Merge Request |

**GitHub MCP è‡ªåŠ¨åŒ–ç¤ºä¾‹**:
```bash
# è‡ªåŠ¨åˆ›å»º Issueï¼ˆåŸºäº TODOï¼‰
gh issue create \
  --title "Implement Knowledge Graph API" \
  --body "$(cat PRPs/knowledge-graph-api.md)" \
  --label "enhancement,backend" \
  --assignee "@me"

# è‡ªåŠ¨åˆ›å»º PR
gh pr create \
  --title "Add Citation Tracking Backend" \
  --body "Implements #42\n\nChanges:\n- FastAPI endpoints\n- PostgreSQL queries\n- Redis caching" \
  --base main \
  --head feature/citation-tracking
```

---

##### ğŸ“š åä½œæ–‡æ¡£å±‚

| æœåŠ¡ | åŠŸèƒ½ | åº”ç”¨åœºæ™¯ |
|------|------|----------|
| **Feishu (é£ä¹¦)** | ä¸­æ–‡æ–‡æ¡£ã€Mermaid å›¾è¡¨ | é¡¹ç›®å‘¨æŠ¥ã€API æ–‡æ¡£ä¸­æ–‡åŒ– |
| **Notion** | çŸ¥è¯†åº“ã€é¡¹ç›®ç®¡ç† | PRDã€API æ–‡æ¡£ã€ä¼šè®®è®°å½• |
| **Slack** | å›¢é˜Ÿé€šçŸ¥ | Citation å¼‚å¸¸å‘Šè­¦ã€æ„å»ºé€šçŸ¥ |

**Feishu è‡ªåŠ¨åŒ–æŠ¥å‘Šç¤ºä¾‹**:
```javascript
// è‡ªåŠ¨ç”Ÿæˆæ¯å‘¨ GEO å¹³å°æŠ¥å‘Š
const report = await feishu.createDocument({
  title: `GEO Platform Weekly Report - Week ${weekNumber}`,
  content: `
# GEO Platform å‘¨æŠ¥

## ğŸ“Š Citation Rate è¶‹åŠ¿

\`\`\`mermaid
graph LR
  A[Week 38: 25%] --> B[Week 40: 28%]
  B --> C[Week 42: 32%]
  C --> D[Week 44: 35%]
  style D fill:#4ade80
\`\`\`

## âœ… æœ¬å‘¨è¿›å±•

- âœ… å®Œæˆ Neo4j çŸ¥è¯†å›¾è°± API
- âœ… æ–°å¢ Hisense é¡¹ç›®æ•°æ®
- âœ… ä¼˜åŒ– Prompt è¯„åˆ†ç®—æ³•ï¼ˆå‡†ç¡®ç‡æå‡ 12%ï¼‰
- ğŸš§ æ­£åœ¨å¼€å‘ Citation è‡ªåŠ¨è¿½è¸ªæœåŠ¡

## ğŸ“ˆ å…³é”®æŒ‡æ ‡

| é¡¹ç›® | Citation Rate | å˜åŒ– | Prompts |
|------|---------------|------|---------|
| Eufy | 35% | â†‘ 3% | 89 |
| SweetNight | 32% | â†‘ 2% | 156 |
| Hisense | 28% | æ–°å¢ | 45 |

## ğŸ¯ ä¸‹å‘¨è®¡åˆ’

1. éƒ¨ç½² Firecrawl è‡ªåŠ¨æŠ“å–æœåŠ¡
2. å®ç°è·¨å¹³å°å†…å®¹å‘å¸ƒè°ƒåº¦å™¨
3. å®Œæˆ Analytics Dashboard å‰ç«¯é¡µé¢

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

åŸºäº Sequential Thinking åˆ†æï¼Œå»ºè®®ï¼š
- å¢åŠ æ—¶é—´æ ‡è®°ï¼ˆ"2025"ï¼‰åˆ°æ‰€æœ‰ Prompts
- èšç„¦é—®é¢˜-è§£å†³æ–¹æ¡ˆç±»å†…å®¹
- æ‰©å¤§ YouTube å’Œ Reddit è¦†ç›–

---
ğŸ¤– Generated by Claude Code
  `,
  folder: "GEO Platform Reports"
});

console.log(`æŠ¥å‘Šå·²åˆ›å»º: ${report.url}`);
```

**Slack å‘Šè­¦ç¤ºä¾‹**:
```javascript
// Citation Rate å¼‚å¸¸ç›‘æ§
const checkCitationRate = async () => {
  const projects = await db.query('SELECT * FROM projects');

  for (const project of projects) {
    const rate = await calculateCitationRate(project.id);

    if (rate < 0.20) {
      await slack.notify({
        channel: "#geo-alerts",
        message: `âš ï¸ *Citation Rate ä½äºé˜ˆå€¼*\n\né¡¹ç›®: ${project.name}\nCitation Rate: ${(rate * 100).toFixed(1)}%\nç›®æ ‡: >28%\n\nå»ºè®®:\n1. æ£€æŸ¥ Prompt è´¨é‡è¯„åˆ†\n2. å®¡æŸ¥å†…å®¹å‘å¸ƒé¢‘ç‡\n3. åˆ†æç«å“è¡¨ç°`,
        priority: "high"
      });
    }
  }
};

// æ¯æ—¥æ‰§è¡Œ
setInterval(checkCitationRate, 24 * 60 * 60 * 1000);
```

---

##### ğŸ” ç›‘æ§è°ƒè¯•å±‚

| æœåŠ¡ | åŠŸèƒ½ | åº”ç”¨åœºæ™¯ |
|------|------|----------|
| **Sentry** | é”™è¯¯è¿½è¸ªã€æ€§èƒ½ç›‘æ§ | å‰ç«¯å´©æºƒè¿½è¸ªã€åç«¯å¼‚å¸¸ |

**Sentry é›†æˆç¤ºä¾‹**:
```javascript
// å‰ç«¯é›†æˆï¼ˆfrontend/src/main.tsxï¼‰
import * as Sentry from "@sentry/react";

Sentry.init({
  dsn: "https://your-dsn@sentry.io/project",
  integrations: [new Sentry.BrowserTracing()],
  tracesSampleRate: 1.0,
});

// åç«¯é›†æˆï¼ˆbackend/app/main.pyï¼‰
import sentry_sdk

sentry_sdk.init(
    dsn="https://your-dsn@sentry.io/project",
    traces_sample_rate=1.0,
)
```

---

##### ğŸ“¦ å¯¹è±¡å­˜å‚¨

| æœåŠ¡ | ç«¯å£ | å®¹é‡ | åº”ç”¨åœºæ™¯ |
|------|------|------|----------|
| **MinIO** (è‡ªå»º) | 9000 (API), 9001 (Console) | 524 GB | æ„å»ºäº§ç‰©ã€æµ‹è¯•æŠ¥å‘Šã€ç”Ÿæˆå†…å®¹ |

**MinIO åº”ç”¨åœºæ™¯**:
```bash
# åŠ è½½ç¯å¢ƒå˜é‡
source ~/minio-setup/load-env.sh

# å­˜å‚¨æ„å»ºäº§ç‰©
mc cp frontend/dist/assets/* local/geo-platform/builds/v1.0.0/

# å­˜å‚¨ AI ç”Ÿæˆçš„å†…å®¹
mc cp generated-content.md local/geo-platform/content/sweetnight/

# å¤‡ä»½æ•°æ®åº“
pg_dump -h localhost -p 5437 -U claude claude_dev | gzip > backup.sql.gz
mc cp backup.sql.gz local/geo-platform/backups/$(date +%Y%m%d)/

# æŸ¥çœ‹å­˜å‚¨ä½¿ç”¨æƒ…å†µ
mc du local/geo-platform
```

**Python SDK é›†æˆ**:
```python
# backend/app/services/storage_service.py
from minio import Minio
from io import BytesIO

minio_client = Minio(
    "localhost:9000",
    access_key="SJ7Y8Y1XF49MW0F5223A",
    secret_key="ZQvQQrMtjLuf3CqnlhHk3zgLYtn1wFGdkQpZ6YZq",
    secure=False
)

def store_generated_content(project_id: str, content: str, filename: str):
    """å­˜å‚¨ AI ç”Ÿæˆçš„å†…å®¹"""
    bucket = f"project-{project_id}"

    # åˆ›å»º bucketï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if not minio_client.bucket_exists(bucket):
        minio_client.make_bucket(bucket)

    # ä¸Šä¼ å†…å®¹
    content_bytes = content.encode('utf-8')
    minio_client.put_object(
        bucket,
        filename,
        BytesIO(content_bytes),
        len(content_bytes),
        content_type="text/markdown"
    )

    return f"minio://{bucket}/{filename}"

# ä½¿ç”¨ç¤ºä¾‹
content_url = store_generated_content(
    "sweetnight",
    ai_generated_content,
    "blog-post-2025-01-15.md"
)
```

---

### ğŸ¯ é¡¹ç›®èµ„æºï¼ˆ/Users/cavin/Desktop/dev/leapgeo2/CLAUDE.mdï¼‰

#### 1. å‰ç«¯æŠ€æœ¯æ ˆ

```
React 19          â†’ æœ€æ–°ç‰ˆæœ¬ï¼Œæ”¯æŒ Concurrent Features
TypeScript        â†’ ç±»å‹å®‰å…¨
Vite 7            â†’ å¿«é€Ÿæ„å»ºï¼ˆHMR < 100msï¼‰
Tailwind CSS 4    â†’ ç°ä»£æ ·å¼ï¼ˆPostCSS é›†æˆï¼‰
Lucide React      â†’ ä¸€è‡´çš„å›¾æ ‡ç³»ç»Ÿ
Recharts          â†’ æ•°æ®å¯è§†åŒ–
React Router DOM  â†’ å®¢æˆ·ç«¯è·¯ç”±ï¼ˆå·²å®‰è£…æœªå¯ç”¨ï¼‰
Zustand           â†’ çŠ¶æ€ç®¡ç†ï¼ˆå·²å®‰è£…æœªå¯ç”¨ï¼‰
Framer Motion     â†’ åŠ¨ç”»ç³»ç»Ÿ
Axios             â†’ HTTP å®¢æˆ·ç«¯
Playwright        â†’ E2E æµ‹è¯•
```

**å¼€å‘å‘½ä»¤**:
```bash
npm run dev           # å¼€å‘æœåŠ¡å™¨ï¼ˆhttp://localhost:5173ï¼‰
npm run build         # ç”Ÿäº§æ„å»º
npm run type-check    # TypeScript æ£€æŸ¥
npm run lint          # ESLint
npm run verify        # type-check + buildï¼ˆå®Œæ•´éªŒè¯ï¼‰
npm run auto-verify   # è‡ªåŠ¨éªŒè¯ï¼ˆå½©è‰²è¾“å‡ºï¼‰
npx playwright test   # E2E æµ‹è¯•
```

---

#### 2. åç«¯æŠ€æœ¯æ ˆ

```
FastAPI 0.109         â†’ ç°ä»£ Web æ¡†æ¶
Uvicorn               â†’ ASGI æœåŠ¡å™¨
SQLAlchemy 2.0        â†’ ORMï¼ˆå¼‚æ­¥æ”¯æŒï¼‰
Pydantic 2.5          â†’ æ•°æ®éªŒè¯
Strawberry GraphQL    â†’ GraphQL æ”¯æŒï¼ˆæœªå¯ç”¨ï¼‰
Python-Jose           â†’ JWT è®¤è¯ï¼ˆæœªå¯ç”¨ï¼‰
Pytest                â†’ æµ‹è¯•æ¡†æ¶
```

**å¼€å‘å‘½ä»¤**:
```bash
uvicorn app.main:app --reload --port 8000  # å¼€å‘æœåŠ¡å™¨
pytest                                     # è¿è¡Œæµ‹è¯•
pytest --cov=app --cov-report=html         # è¦†ç›–ç‡æŠ¥å‘Š
```

**API ç«¯ç‚¹**:
```
GET    /api/v1/projects                    # åˆ—å‡ºé¡¹ç›®
GET    /api/v1/projects/{id}               # é¡¹ç›®è¯¦æƒ…
POST   /api/v1/projects                    # åˆ›å»ºé¡¹ç›®
GET    /api/v1/projects/{id}/prompts       # é¡¹ç›® Prompts
GET    /api/v1/projects/{id}/citations     # é¡¹ç›® Citations
GET    /api/v1/stats/overview              # ç»Ÿè®¡æ¦‚è§ˆ
GET    /api/v1/stats/leaderboard           # Citation Rate æ’è¡Œæ¦œ
```

---

#### 3. æ•°æ®åº“èµ„æº

```
PostgreSQL 5437    â†’ ä¸šåŠ¡æ•°æ®ï¼ˆ9 å¼ è¡¨ï¼‰
Neo4j 7688         â†’ çŸ¥è¯†å›¾è°±ï¼ˆ6 ç§èŠ‚ç‚¹ç±»å‹ï¼Œ7 ç§å…³ç³»ï¼‰
Redis 6382         â†’ ç¼“å­˜å±‚ï¼ˆ4 ç§é”®æ¨¡å¼ï¼‰
```

**åˆå§‹åŒ–è„šæœ¬**:
```bash
# PostgreSQL
PGPASSWORD=claude_dev_2025 psql -h localhost -p 5437 -U claude -d claude_dev -f scripts/init_database.sql

# Neo4j
cat scripts/init_neo4j.cypher | docker exec -i neo4j-claude-mcp cypher-shell -u neo4j -p claude_neo4j_2025

# Redis
python3 scripts/init_redis.py

# æ•°æ®è¿ç§»
python3 scripts/migrate_data.py

# æ•°æ®éªŒè¯
python3 scripts/verify_data.py
```

---

#### 4. æ¶æ„æ¨¡å¼

**å‰ç«¯ - Portal å¸ƒå±€æ¨¡å¼**:
```
Portal.tsx (è·¯ç”±å®¹å™¨)
  â”œâ”€â”€ Sidebar (å¯¼èˆª)
  â”œâ”€â”€ Header (æ ‡é¢˜æ )
  â””â”€â”€ Page Content (åŠ¨æ€é¡µé¢)
      â”œâ”€â”€ Dashboard
      â”œâ”€â”€ Projects
      â”œâ”€â”€ KnowledgeGraph
      â”œâ”€â”€ PromptManagement
      â”œâ”€â”€ ContentGenerator
      â”œâ”€â”€ CitationTracking
      â””â”€â”€ Analytics
```

**å…³é”®è®¾è®¡åŸåˆ™**:
- Portal åªè´Ÿè´£å¸ƒå±€å’Œè·¯ç”±
- æ¯ä¸ªé¡µé¢ç»„ä»¶å®Œå…¨ç‹¬ç«‹
- é¿å…è·¨é¡µé¢çŠ¶æ€å…±äº«ï¼ˆç›®å‰ï¼‰
- æœªæ¥å‡çº§åˆ° React Router

**åç«¯ - RESTful API + æ•°æ®å±‚åˆ†å·¥**:
```
FastAPI Application
  â”œâ”€â”€ Projects Router     â†’ PostgreSQL
  â”œâ”€â”€ Prompts Router      â†’ PostgreSQL
  â”œâ”€â”€ Citations Router    â†’ PostgreSQL + Redis (cache)
  â”œâ”€â”€ Stats Router        â†’ PostgreSQL + Redis (cache)
  â””â”€â”€ Knowledge Graph     â†’ Neo4j (æœªå®ç°)
```

---

#### 5. ä¸šåŠ¡é€»è¾‘

**ä¸ƒé˜¶æ®µ GEO å·¥ä½œæµ**:
1. Prompt ç®¡ç† â†’ AI è¯„åˆ†ï¼ˆ0-100ï¼‰â†’ ä¼˜å…ˆçº§ï¼ˆP0/P1/P2ï¼‰
2. çŸ¥è¯†å›¾è°±æŸ¥è¯¢ â†’ ä» Neo4j æå–äº§å“ç‰¹æ€§
3. å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆ â†’ GPT-4o/Claude
4. å†…å®¹è´¨é‡è¯„åˆ† â†’ GEO ä¼˜åŒ–åˆ†æ•°
5. è·¨å¹³å°å‘å¸ƒ â†’ 9+ å¹³å°è°ƒåº¦
6. AI Citation è¿½è¸ª â†’ 8 ä¸ª AI å¹³å°æ‰«æ
7. æ•°æ®åˆ†æä¼˜åŒ– â†’ æŒç»­è¿­ä»£

**çŸ¥è¯†å›¾è°±ç»“æ„**:
```cypher
(Brand)-[:HAS_PRODUCT]->(Product)
(Product)-[:HAS_FEATURE]->(Feature)
(Feature)-[:SOLVES]->(Problem)
(Feature)-[:APPLIES_TO]->(Scenario)
(UserGroup)-[:NEEDS]->(Feature)
(UserGroup)-[:HAS_PROBLEM]->(Problem)
```

**Citation Rate è®¡ç®—**:
```python
citation_rate = cited_prompts / total_prompts

åŸºå‡†:
- >35%: ä¼˜ç§€ï¼ˆç»¿è‰²ï¼‰
- 28-35%: è‰¯å¥½ï¼ˆè“è‰²ï¼‰
- 20-28%: å¹³å‡ï¼ˆé»„è‰²ï¼‰
- <20%: éœ€æ”¹è¿›ï¼ˆçº¢è‰²ï¼‰
```

---

## ğŸš€ è‡ªåŠ¨åŒ–å¼€å‘å·¥ä½œæµ

### å·¥ä½œæµ 1: æ–°åŠŸèƒ½å®Œæ•´å¼€å‘ï¼ˆContext Engineering é©±åŠ¨ï¼‰

**åœºæ™¯**: å®ç° Knowledge Graph APIï¼ˆä»é›¶åˆ°ç”Ÿäº§ï¼‰

**æ­¥éª¤**:

#### Phase 1: éœ€æ±‚åˆ†æä¸è®¾è®¡ï¼ˆ15åˆ†é’Ÿï¼‰

```bash
# 1. ä½¿ç”¨ä¸šåŠ¡åˆ†æå¸ˆè§’è‰²
/analyst --research "Neo4j çŸ¥è¯†å›¾è°±åœ¨ GEO å¹³å°ä¸­çš„åº”ç”¨æ¡ˆä¾‹"

# è¾“å‡º: ç«å“åˆ†æã€æŠ€æœ¯è°ƒç ”æŠ¥å‘Š

# 2. ä½¿ç”¨æ¶æ„å¸ˆè§’è‰²
/architect --design "FastAPI + Neo4j GraphQL API æ¶æ„"

# è¾“å‡º:
# - ç³»ç»Ÿæ¶æ„å›¾
# - API ç«¯ç‚¹è®¾è®¡
# - æ•°æ®æ¨¡å‹è®¾è®¡
# - å®‰å…¨æ€§è€ƒè™‘
```

#### Phase 2: åˆ›å»º PRPï¼ˆProduct Requirements Promptï¼‰ï¼ˆ10åˆ†é’Ÿï¼‰

```bash
# åˆ›å»º INITIAL.md
cat > INITIAL.md << 'EOF'
# FEATURE: Knowledge Graph API

## éœ€æ±‚æè¿°
å®ç° Neo4j çŸ¥è¯†å›¾è°± CRUD APIï¼Œæ”¯æŒï¼š
- æŸ¥è¯¢å“ç‰Œ-äº§å“-ç‰¹æ€§å…³ç³»
- æ·»åŠ æ–°èŠ‚ç‚¹å’Œå…³ç³»
- æ›´æ–°èŠ‚ç‚¹å±æ€§
- åˆ é™¤èŠ‚ç‚¹å’Œå…³ç³»
- GraphQL æŸ¥è¯¢æ¥å£

## EXAMPLESï¼ˆå‚è€ƒç°æœ‰ä»£ç ï¼‰
- frontend/src/components/pages/KnowledgeGraph.tsxï¼ˆå‰ç«¯å¯è§†åŒ–ï¼‰
- scripts/init_neo4j.cypherï¼ˆæ•°æ®ç»“æ„ï¼‰
- backend/app/services/neo4j_service.pyï¼ˆç°æœ‰æœåŠ¡ï¼‰

## DOCUMENTATION
- Neo4j Python Driver: https://neo4j.com/docs/python-manual/current/
- Strawberry GraphQL: https://strawberry.rocks/docs
- FastAPI é›†æˆ: https://fastapi.tiangolo.com/

## OTHER CONSIDERATIONS
- éœ€è¦å¤„ç†å¹¶å‘å†™å…¥
- æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–ï¼ˆä½¿ç”¨ç´¢å¼•ï¼‰
- é”™è¯¯å¤„ç†ï¼ˆè¿æ¥å¤±è´¥ã€æ— æ•ˆ Cypherï¼‰
- ä¸ PostgreSQL æ•°æ®ä¸€è‡´æ€§
- Redis ç¼“å­˜çƒ­ç‚¹æŸ¥è¯¢
EOF

# ç”Ÿæˆ PRP
/generate-prp INITIAL.md

# è¾“å‡º: PRPs/knowledge-graph-api.md
# åŒ…å«:
# - å®Œæ•´çš„å®æ–½è®¡åˆ’
# - ä»£ç ç¤ºä¾‹
# - éªŒè¯æ¸…å•
# - ç½®ä¿¡åº¦è¯„åˆ†ï¼ˆ1-10ï¼‰
```

#### Phase 3: è‡ªåŠ¨å®ç°ï¼ˆ30åˆ†é’Ÿï¼‰

```bash
# æ‰§è¡Œ PRP
/execute-prp PRPs/knowledge-graph-api.md

# è‡ªåŠ¨æ‰§è¡Œ:
# 1. ä½¿ç”¨ TodoWrite åˆ›å»ºä»»åŠ¡åˆ—è¡¨:
#    - [ ] åˆ›å»º Pydantic GraphQL Schema
#    - [ ] å®ç° Neo4j æŸ¥è¯¢å‡½æ•°
#    - [ ] åˆ›å»º FastAPI GraphQL ç«¯ç‚¹
#    - [ ] æ·»åŠ  Redis ç¼“å­˜å±‚
#    - [ ] ç¼–å†™å•å…ƒæµ‹è¯•
#    - [ ] ç¼–å†™é›†æˆæµ‹è¯•
#    - [ ] æ›´æ–° API æ–‡æ¡£

# 2. ä½¿ç”¨ Neo4j MCP åˆ›å»º/æµ‹è¯•æŸ¥è¯¢
# 3. ä½¿ç”¨ PostgreSQL MCP ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
# 4. ä½¿ç”¨ Redis MCP å®ç°ç¼“å­˜
# 5. é€ä¸ªå®Œæˆä»»åŠ¡ï¼Œæ ‡è®°è¿›åº¦
```

**ç”Ÿæˆçš„æ–‡ä»¶**:
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ graphql/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ schema.py          # Strawberry GraphQL Schema
â”‚   â”‚   â””â”€â”€ resolvers.py       # Query/Mutation Resolvers
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ neo4j_service.py   # æ‰©å±•çš„ Neo4j æœåŠ¡
â”‚   â””â”€â”€ routers/
â”‚       â””â”€â”€ knowledge_graph.py # FastAPI è·¯ç”±
â””â”€â”€ tests/
    â”œâ”€â”€ test_graphql_schema.py
    â””â”€â”€ test_neo4j_service.py
```

#### Phase 4: æµ‹è¯•ä¸éªŒè¯ï¼ˆ10åˆ†é’Ÿï¼‰

```bash
# 1. åç«¯æµ‹è¯•
cd backend
pytest tests/test_neo4j_service.py -v
pytest tests/test_graphql_schema.py -v

# 2. é›†æˆæµ‹è¯•
pytest tests/integration/test_knowledge_graph_api.py -v

# 3. æ€§èƒ½æµ‹è¯•
pytest tests/performance/test_neo4j_queries.py -v

# 4. API æ–‡æ¡£éªŒè¯
open http://localhost:8000/docs
# éªŒè¯ /graphql ç«¯ç‚¹æ˜¯å¦å‡ºç°
```

#### Phase 5: æ–‡æ¡£ä¸æäº¤ï¼ˆ5åˆ†é’Ÿï¼‰

```bash
# 1. ç”Ÿæˆ API æ–‡æ¡£
/sc:document --output "docs/Knowledge-Graph-API.md"

# 2. Feishu ä¸­æ–‡æ–‡æ¡£
node << 'EOF'
const feishu = require('./mcp-feishu-client');

feishu.createDocument({
  title: "Knowledge Graph API æ–‡æ¡£",
  content: `
# Knowledge Graph API

## æ¦‚è¿°
åŸºäº Neo4j çš„çŸ¥è¯†å›¾è°± APIï¼Œæ”¯æŒ RESTful å’Œ GraphQL ä¸¤ç§æŸ¥è¯¢æ–¹å¼ã€‚

## GraphQL Schema

\`\`\`graphql
type Brand {
  id: ID!
  name: String!
  products: [Product!]!
}

type Product {
  id: ID!
  name: String!
  features: [Feature!]!
  brand: Brand!
}

type Query {
  brand(id: ID!): Brand
  searchFeatures(problem: String!): [Feature!]!
}
\`\`\`

## REST API

### æŸ¥è¯¢å“ç‰Œå…³ç³»
\`\`\`bash
curl http://localhost:8000/api/v1/knowledge-graph/brands/sweetnight
\`\`\`

### GraphQL æŸ¥è¯¢
\`\`\`bash
curl -X POST http://localhost:8000/graphql \\
  -H "Content-Type: application/json" \\
  -d '{"query": "{ brand(id: \\"sweetnight\\") { name products { name } } }"}'
\`\`\`

## æ€§èƒ½æŒ‡æ ‡
- å¹³å‡æŸ¥è¯¢æ—¶é—´: 45ms (P95: 120ms)
- ç¼“å­˜å‘½ä¸­ç‡: 78%
- å¹¶å‘æ”¯æŒ: 100 req/s
  `
});
EOF

# 3. æ™ºèƒ½ Git æäº¤
/sc:git --message "Add Knowledge Graph API with GraphQL support"

# è‡ªåŠ¨ç”Ÿæˆ commit message:
# feat: Add Knowledge Graph API with GraphQL support
#
# - Implement Strawberry GraphQL schema for knowledge graph
# - Add Neo4j service methods for CRUD operations
# - Integrate Redis caching for hot queries
# - Add comprehensive unit and integration tests
# - Update API documentation
#
# Performance:
# - Query time P95: 120ms
# - Cache hit rate: 78%
# - Supports 100 concurrent requests/sec
#
# ğŸ¤– Generated with Claude Code
# Co-Authored-By: Claude <noreply@anthropic.com>
```

---

### å·¥ä½œæµ 2: Citation è¿½è¸ªç³»ç»Ÿï¼ˆå¤š MCP ååŒï¼‰

**åœºæ™¯**: å®ç°è‡ªåŠ¨åŒ– AI å¹³å° Citation è¿½è¸ª

#### Phase 1: ä»»åŠ¡åˆ†è§£ï¼ˆ5åˆ†é’Ÿï¼‰

```bash
# ä½¿ç”¨ä»»åŠ¡åˆ†è§£å·¥å…·
/sc:spawn --task "å®ç° AI å¹³å° Citation è‡ªåŠ¨è¿½è¸ªç³»ç»Ÿ"

# è¾“å‡ºå­ä»»åŠ¡:
# 1. é…ç½® Firecrawl æŠ“å– 8 ä¸ª AI å¹³å°
# 2. è®¾è®¡ Citation æ•°æ®æå–è§„åˆ™
# 3. å®ç° PostgreSQL å­˜å‚¨é€»è¾‘
# 4. å®ç° Redis å®æ—¶ç»Ÿè®¡ç¼“å­˜
# 5. æ·»åŠ  Slack å¼‚å¸¸å‘Šè­¦
# 6. åˆ›å»º Celery å®šæ—¶ä»»åŠ¡
# 7. å‰ç«¯ Citation Dashboard é›†æˆ
```

#### Phase 2: Firecrawl æŠ“å–é…ç½®ï¼ˆ10åˆ†é’Ÿï¼‰

```bash
# å¯åŠ¨ Firecrawl
cd /Users/cavin/firecrawl
docker compose up -d

# åˆ›å»ºæŠ“å–è„šæœ¬
cat > backend/app/services/citation_crawler.py << 'EOF'
import requests
from typing import List, Dict

FIRECRAWL_API = "http://localhost:3002"
FIRECRAWL_API_KEY = "fs-test"

AI_PLATFORMS = [
    {"name": "ChatGPT", "url_template": "https://chat.openai.com/search?q={prompt}"},
    {"name": "Claude", "url_template": "https://claude.ai/search?q={prompt}"},
    {"name": "Perplexity", "url_template": "https://perplexity.ai/?q={prompt}"},
    {"name": "Gemini", "url_template": "https://gemini.google.com/app?q={prompt}"},
    {"name": "Copilot", "url_template": "https://copilot.microsoft.com/?q={prompt}"},
    {"name": "You.com", "url_template": "https://you.com/search?q={prompt}"},
    {"name": "Phind", "url_template": "https://phind.com/search?q={prompt}"},
    {"name": "Anthropic", "url_template": "https://anthropic.com/search?q={prompt}"}
]

async def crawl_platform(platform: str, prompt: str) -> Dict:
    """ä½¿ç”¨ Firecrawl æŠ“å–å•ä¸ªå¹³å°"""
    platform_config = next(p for p in AI_PLATFORMS if p["name"] == platform)
    url = platform_config["url_template"].format(prompt=prompt)

    response = requests.post(
        f"{FIRECRAWL_API}/v1/scrape",
        json={
            "url": url,
            "waitFor": "networkidle",
            "extractors": [
                {
                    "type": "css",
                    "selector": "a[href*='youtube.com'], a[href*='reddit.com']",
                    "attribute": "href"
                },
                {
                    "type": "text",
                    "selector": ".citation, .source, .reference"
                }
            ]
        },
        headers={"Authorization": f"Bearer {FIRECRAWL_API_KEY}"}
    )

    return response.json()

async def detect_citations(project_id: str, prompts: List[str]):
    """æ‰¹é‡æ£€æµ‹ Citations"""
    results = []

    for prompt_text in prompts:
        for platform in AI_PLATFORMS:
            data = await crawl_platform(platform["name"], prompt_text)

            # æå– Citations
            citations = extract_citations_from_html(data["content"], project_id)
            results.extend(citations)

    return results

def extract_citations_from_html(html: str, project_id: str) -> List[Dict]:
    """ä» HTML ä¸­æå– Citations"""
    # ä½¿ç”¨ Sequential Thinking åˆ†æå¼•ç”¨æ¨¡å¼
    from mcp_sequential_thinking import analyze

    analysis = analyze({
        "task": "è¯†åˆ« AI å“åº”ä¸­çš„å“ç‰Œå¼•ç”¨",
        "html": html,
        "project_id": project_id
    })

    return analysis["citations"]
EOF
```

#### Phase 3: æ•°æ®å­˜å‚¨ä¸ç¼“å­˜ï¼ˆ10åˆ†é’Ÿï¼‰

```python
# backend/app/services/citation_storage.py
import redis
from sqlalchemy.orm import Session
from ..models.citation import Citation
from ..database import get_db

redis_client = redis.Redis(
    host='localhost',
    port=6382,
    password='claude_redis_2025',
    decode_responses=True
)

async def store_citations(citations: List[Dict], db: Session):
    """å­˜å‚¨ Citations åˆ° PostgreSQL + Redis"""
    for citation_data in citations:
        # PostgreSQL: æŒä¹…åŒ–å­˜å‚¨
        citation = Citation(**citation_data)
        db.add(citation)

        # Redis: å®æ—¶ç»Ÿè®¡
        project_id = citation_data["project_id"]
        platform = citation_data["platform"]

        # å¢åŠ è®¡æ•°
        redis_client.incr(f"geo:project:{project_id}:citations_count")
        redis_client.incr(f"geo:platform:{platform}:citations_count")

        # æ›´æ–°æ’è¡Œæ¦œ
        redis_client.zadd(
            "geo:citation_rate_leaderboard",
            {project_id: await calculate_citation_rate(project_id, db)}
        )

    db.commit()

async def get_cached_citation_stats(project_id: str) -> Dict:
    """ä» Redis è·å–å®æ—¶ç»Ÿè®¡"""
    key = f"geo:project:{project_id}:citation_stats"
    cached = redis_client.get(key)

    if cached:
        return json.loads(cached)

    # Cache miss - ä»æ•°æ®åº“è®¡ç®—
    stats = await calculate_stats_from_db(project_id)
    redis_client.setex(key, 1800, json.dumps(stats))  # 30åˆ†é’Ÿ TTL
    return stats
```

#### Phase 4: Slack å‘Šè­¦é›†æˆï¼ˆ5åˆ†é’Ÿï¼‰

```python
# backend/app/services/alerting.py
from slack_sdk import WebClient

slack_client = WebClient(token=os.getenv("SLACK_BOT_TOKEN"))

async def check_and_alert():
    """æ£€æŸ¥ Citation Rate å¹¶å‘é€å‘Šè­¦"""
    projects = await db.query(Project).all()

    for project in projects:
        rate = await calculate_citation_rate(project.id)

        if rate < 0.20:
            slack_client.chat_postMessage(
                channel="#geo-alerts",
                text=f"âš ï¸ *Citation Rate å‘Šè­¦*\n\n"
                     f"é¡¹ç›®: {project.name}\n"
                     f"Citation Rate: {rate * 100:.1f}%\n"
                     f"ç›®æ ‡: >28%\n\n"
                     f"å»ºè®®è¡ŒåŠ¨:\n"
                     f"1. å®¡æŸ¥è¿‘æœŸ Prompts è´¨é‡\n"
                     f"2. æ£€æŸ¥å†…å®¹å‘å¸ƒé¢‘ç‡\n"
                     f"3. åˆ†æç«å“è¡¨ç°\n"
                     f"4. æŸ¥çœ‹è¯¦æƒ…: http://localhost:5173/citations?project={project.id}"
            )
```

#### Phase 5: Celery å®šæ—¶ä»»åŠ¡ï¼ˆ10åˆ†é’Ÿï¼‰

```python
# backend/app/tasks/citation_tracking.py
from celery import Celery
from celery.schedules import crontab

celery_app = Celery('geo_platform', broker='redis://localhost:6382/0')

celery_app.conf.beat_schedule = {
    'track-citations-daily': {
        'task': 'app.tasks.citation_tracking.track_all_citations',
        'schedule': crontab(hour=2, minute=0),  # æ¯å¤©å‡Œæ™¨ 2 ç‚¹
    },
    'check-citation-rate-hourly': {
        'task': 'app.tasks.citation_tracking.check_citation_rate',
        'schedule': crontab(minute=0),  # æ¯å°æ—¶
    }
}

@celery_app.task
async def track_all_citations():
    """è¿½è¸ªæ‰€æœ‰é¡¹ç›®çš„ Citations"""
    projects = await db.query(Project).filter_by(status='active').all()

    for project in projects:
        prompts = await db.query(Prompt).filter_by(
            project_id=project.id,
            status='active'
        ).all()

        prompt_texts = [p.text for p in prompts]

        # ä½¿ç”¨ Firecrawl æ‰¹é‡æŠ“å–
        citations = await detect_citations(project.id, prompt_texts)

        # å­˜å‚¨åˆ°æ•°æ®åº“ + Redis
        await store_citations(citations, db)

        # ä½¿ç”¨ Memory MCP è®°å½•
        await memory.save({
            "topic": f"Citation Tracking - {project.name}",
            "date": datetime.now().isoformat(),
            "citations_detected": len(citations),
            "citation_rate": await calculate_citation_rate(project.id)
        })

@celery_app.task
async def check_citation_rate():
    """æ£€æŸ¥ Citation Rate å¹¶å‘Šè­¦"""
    await check_and_alert()

# å¯åŠ¨ Celery Worker
# celery -A app.tasks.citation_tracking worker --loglevel=info

# å¯åŠ¨ Celery Beat
# celery -A app.tasks.citation_tracking beat --loglevel=info
```

#### Phase 6: å‰ç«¯é›†æˆï¼ˆ15åˆ†é’Ÿï¼‰

```typescript
// frontend/src/api/citations.ts
import axios from 'axios';

const API_URL = 'http://localhost:8000/api/v1';

export const getCitations = async (projectId: string, filters?: any) => {
  const response = await axios.get(`${API_URL}/projects/${projectId}/citations`, {
    params: filters
  });
  return response.data;
};

export const getCitationStats = async (projectId: string) => {
  const response = await axios.get(`${API_URL}/stats/citations/${projectId}`);
  return response.data;
};

// frontend/src/components/pages/CitationTracking.tsx
import { useEffect, useState } from 'react';
import { getCitations, getCitationStats } from '../../api/citations';

const CitationTracking: React.FC = () => {
  const [citations, setCitations] = useState([]);
  const [stats, setStats] = useState(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const loadData = async () => {
      try {
        const [citationsData, statsData] = await Promise.all([
          getCitations(selectedProject),
          getCitationStats(selectedProject)
        ]);

        setCitations(citationsData);
        setStats(statsData);
      } catch (error) {
        console.error('Failed to load citation data:', error);
      } finally {
        setLoading(false);
      }
    };

    loadData();

    // æ¯ 5 åˆ†é’Ÿåˆ·æ–°ä¸€æ¬¡
    const interval = setInterval(loadData, 5 * 60 * 1000);
    return () => clearInterval(interval);
  }, [selectedProject]);

  if (loading) return <div>Loading...</div>;

  return (
    <div className="space-y-6">
      {/* Citation Stats Cards */}
      <div className="grid grid-cols-4 gap-6">
        <StatCard
          label="Total Citations"
          value={stats.total_citations}
          change={stats.citation_change}
        />
        <StatCard
          label="Citation Rate"
          value={`${(stats.citation_rate * 100).toFixed(1)}%`}
          change={stats.rate_change}
        />
        {/* ... more cards */}
      </div>

      {/* Platform Breakdown */}
      <PlatformBreakdownChart data={stats.platform_breakdown} />

      {/* Citations List */}
      <CitationsList citations={citations} />
    </div>
  );
};
```

#### Phase 7: æµ‹è¯•ä¸éƒ¨ç½²ï¼ˆ10åˆ†é’Ÿï¼‰

```bash
# 1. å•å…ƒæµ‹è¯•
pytest backend/tests/test_citation_crawler.py -v
pytest backend/tests/test_citation_storage.py -v

# 2. é›†æˆæµ‹è¯•
pytest backend/tests/integration/test_citation_tracking_flow.py -v

# 3. E2E æµ‹è¯•ï¼ˆPlaywrightï¼‰
npx playwright test tests/e2e/citation-tracking.spec.ts

# 4. æ€§èƒ½æµ‹è¯•
pytest backend/tests/performance/test_firecrawl_throughput.py -v
# é¢„æœŸ: 8 ä¸ªå¹³å° x 10 ä¸ª Prompts = 80 æ¬¡æŠ“å– < 5 åˆ†é’Ÿ

# 5. å¯åŠ¨ Celery
celery -A app.tasks.citation_tracking worker --loglevel=info &
celery -A app.tasks.citation_tracking beat --loglevel=info &

# 6. éªŒè¯
open http://localhost:5173/citations

# 7. æ–‡æ¡£ä¸æäº¤
/sc:document --output "docs/Citation-Tracking-System.md"
/sc:git --message "Add automated AI platform citation tracking system"
```

---

### å·¥ä½œæµ 3: ä»£ç è´¨é‡æ”¹è¿›å¾ªç¯

**åœºæ™¯**: æŒç»­ä»£ç è´¨é‡æå‡

```bash
# æ¯å‘¨æ‰§è¡Œä¸€æ¬¡

# 1. å…¨é¢ä»£ç åˆ†æ
/sc:analyze --scope "frontend/src/components" --output "reports/frontend-analysis.md"
/sc:analyze --scope "backend/app" --output "reports/backend-analysis.md"

# è¾“å‡º:
# - ç±»å‹é”™è¯¯: 23 å¤„
# - ESLint è­¦å‘Š: 45 å¤„
# - å¤æ‚åº¦è¿‡é«˜å‡½æ•°: 8 ä¸ª
# - æœªä½¿ç”¨å˜é‡: 12 ä¸ª
# - å¯è®¿é—®æ€§é—®é¢˜: 18 å¤„

# 2. è‡ªåŠ¨æ”¹è¿›
/sc:improve --priority high --scope "frontend/src"

# è‡ªåŠ¨æ‰§è¡Œ:
# - ç§»é™¤ @ts-nocheck æŒ‡ä»¤
# - æ·»åŠ ç¼ºå¤±çš„ç±»å‹æ³¨è§£
# - ä¿®å¤ ESLint é”™è¯¯
# - æ·»åŠ  ARIA æ ‡ç­¾
# - ä¼˜åŒ–å¤æ‚å‡½æ•°

# 3. æ¸…ç†æ­»ä»£ç 
/sc:cleanup --scope "frontend/src" --dry-run

# è¾“å‡º:
# - æœªä½¿ç”¨ç»„ä»¶: 5 ä¸ª
# - æœªä½¿ç”¨å‡½æ•°: 12 ä¸ª
# - æœªä½¿ç”¨å¯¼å…¥: 34 ä¸ª
# - å¯åˆ é™¤çš„ Mock æ•°æ®: 8 ä¸ªæ–‡ä»¶

/sc:cleanup --scope "frontend/src" --confirm

# 4. è¿è¡Œæµ‹è¯•
/sc:test --coverage --min-coverage 80

# 5. æäº¤
/sc:git --message "Improve code quality and remove dead code"
```

---

### å·¥ä½œæµ 4: æ–°é¡¹ç›®å¿«é€Ÿå¯åŠ¨

**åœºæ™¯**: ä¸ºæ–°å®¢æˆ·ï¼ˆå¦‚ Sony TVï¼‰å¿«é€Ÿåˆ›å»ºé¡¹ç›®

```bash
# ä½¿ç”¨å¤šè§’è‰²åä½œ

# 1. å¸‚åœºåˆ†æï¼ˆ5åˆ†é’Ÿï¼‰
/analyst --research "Sony TV åœ¨ AI æœç´¢å¼•æ“ä¸­çš„å¼•ç”¨ç°çŠ¶å’Œç«å“åˆ†æ"

# è¾“å‡º:
# - å½“å‰ Citation Rate: 18% (ä½äºè¡Œä¸šå¹³å‡)
# - ä¸»è¦ç«å“: Samsung (32%), LG (28%)
# - çƒ­é—¨æœç´¢è¯: "best TV for gaming", "OLED vs QLED"

# 2. äº§å“è§„åˆ’ï¼ˆ5åˆ†é’Ÿï¼‰
/po --create-product-plan "Sony TV GEO Optimization"

# è¾“å‡º:
# - äº§å“æ„¿æ™¯
# - ç›®æ ‡ç”¨æˆ·ç¾¤ï¼ˆGamers, Home Theater Enthusiastsï¼‰
# - ä¼˜å…ˆçº§æ’åºï¼ˆGaming Performance > Picture Quality > Smart Featuresï¼‰

# 3. é¡¹ç›®ç®¡ç†ï¼ˆ10åˆ†é’Ÿï¼‰
/pm --create-prd "Sony TV GEO Project"

# è¾“å‡º:
# - PRD æ–‡æ¡£
# - Milestone å®šä¹‰
# - èµ„æºéœ€æ±‚
# - æ—¶é—´ä¼°ç®—ï¼ˆ6-8 å‘¨è¾¾åˆ° 28% Citation Rateï¼‰

# 4. æ•°æ®å‡†å¤‡ï¼ˆ15åˆ†é’Ÿï¼‰
# ä½¿ç”¨ Neo4j MCP åˆ›å»ºçŸ¥è¯†å›¾è°±
cat > scripts/sony_knowledge_graph.cypher << 'EOF'
// å“ç‰Œ
CREATE (sony:Brand {id: 'sony', name: 'Sony'});

// äº§å“
CREATE (bravia:Product {id: 'bravia-xr', name: 'Bravia XR'});
CREATE (a95l:Product {id: 'a95l', name: 'A95L OLED'});

// ç‰¹æ€§
CREATE (xrProcessor:Feature {id: 'xr-processor', name: 'XR Processor'});
CREATE (perfectForPS5:Feature {id: 'ps5-ready', name: 'Perfect for PS5'});
CREATE (cognitive:Feature {id: 'cognitive', name: 'Cognitive Intelligence'});

// é—®é¢˜
CREATE (inputLag:Problem {id: 'input-lag', name: 'Input Lag'});
CREATE (motionBlur:Problem {id: 'motion-blur', name: 'Motion Blur'});

// ç”¨æˆ·ç¾¤
CREATE (gamers:UserGroup {id: 'gamers', name: 'Gamers'});
CREATE (filmmakers:UserGroup {id: 'filmmakers', name: 'Filmmakers'});

// å…³ç³»
CREATE (sony)-[:HAS_PRODUCT]->(bravia);
CREATE (sony)-[:HAS_PRODUCT]->(a95l);
CREATE (bravia)-[:HAS_FEATURE]->(xrProcessor);
CREATE (a95l)-[:HAS_FEATURE]->(perfectForPS5);
CREATE (perfectForPS5)-[:SOLVES]->(inputLag);
CREATE (gamers)-[:NEEDS]->(perfectForPS5);
EOF

cat scripts/sony_knowledge_graph.cypher | docker exec -i neo4j-claude-mcp cypher-shell -u neo4j -p claude_neo4j_2025

# ä½¿ç”¨ PostgreSQL MCP åˆ›å»ºé¡¹ç›®
PGPASSWORD=claude_dev_2025 psql -h localhost -p 5437 -U claude -d claude_dev << 'EOF'
INSERT INTO projects (id, name, industry, description, status, citation_rate, total_prompts)
VALUES (
  'sony',
  'Sony TV',
  'Consumer Electronics - Home Entertainment',
  'GEO optimization for Sony Bravia TV series',
  'active',
  0.18,
  0
);
EOF

# 5. Prompt ç”Ÿæˆï¼ˆ10åˆ†é’Ÿï¼‰
# ä½¿ç”¨ Sequential Thinking ç”Ÿæˆé«˜è´¨é‡ Prompts
node << 'EOF'
const sequentialThinking = require('./mcp-sequential-thinking');

const result = sequentialThinking.analyze({
  task: "ä¸º Sony TV ç”Ÿæˆ 50 ä¸ªé«˜ Citation Rate Prompts",
  context: {
    product: "Sony Bravia XR",
    target_users: ["Gamers", "Home Theater Enthusiasts"],
    key_features: ["XR Processor", "Perfect for PS5", "4K 120Hz"]
  },
  steps: [
    "åˆ†æç«å“é«˜è¡¨ç° Prompts",
    "è¯†åˆ« Sony ç‹¬ç‰¹å–ç‚¹",
    "ç”Ÿæˆé—®é¢˜-è§£å†³æ–¹æ¡ˆç±» Prompts",
    "æ·»åŠ æ—¶é—´æ ‡è®°ï¼ˆ2025ï¼‰",
    "æŒ‰ä¼˜å…ˆçº§æ’åº"
  ]
});

console.log(result.prompts);
// Output:
// P0: "best TV for PS5 gaming 2025"
// P0: "Sony Bravia XR vs Samsung QLED comparison"
// P1: "how to reduce input lag on TV for gaming"
// ...
EOF

# æ‰¹é‡å¯¼å…¥ Prompts
python3 << 'EOF'
import psycopg2

conn = psycopg2.connect(
    host="localhost",
    port=5437,
    user="claude",
    password="claude_dev_2025",
    database="claude_dev"
)

prompts = [
    {"text": "best TV for PS5 gaming 2025", "priority": "P0", "score": 95},
    {"text": "Sony Bravia XR vs Samsung QLED", "priority": "P0", "score": 92},
    # ... 48 more prompts
]

cursor = conn.cursor()
for prompt in prompts:
    cursor.execute("""
        INSERT INTO prompts (project_id, text, intent, priority, score, status)
        VALUES ('sony', %s, 'High-Intent', %s, %s, 'active')
    """, (prompt["text"], prompt["priority"], prompt["score"]))

conn.commit()
conn.close()
EOF

# 6. å‰ç«¯æ›´æ–°ï¼ˆ5åˆ†é’Ÿï¼‰
# é¡¹ç›®å·²è‡ªåŠ¨å‡ºç°åœ¨ Dashboardï¼ˆä»æ•°æ®åº“åŠ¨æ€åŠ è½½ï¼‰
open http://localhost:5173/dashboard

# 7. é¦–æ¬¡ Citation è¿½è¸ªï¼ˆç«‹å³æ‰§è¡Œï¼‰
celery -A app.tasks.citation_tracking call app.tasks.citation_tracking.track_all_citations --args='["sony"]'

# 8. ç”Ÿæˆé¡¹ç›®å¯åŠ¨æŠ¥å‘Š
/sc:document --template "project-kickoff" --output "reports/Sony-TV-Kickoff.md"

# 9. Feishu é€šçŸ¥å›¢é˜Ÿ
node << 'EOF'
const feishu = require('./mcp-feishu-client');

feishu.createDocument({
  title: "ğŸš€ Sony TV GEO é¡¹ç›®å¯åŠ¨",
  content: `
# Sony TV GEO é¡¹ç›®å¯åŠ¨é€šçŸ¥

## é¡¹ç›®æ¦‚å†µ
- **å®¢æˆ·**: Sony
- **äº§å“**: Bravia XR TV ç³»åˆ—
- **ç›®æ ‡**: 6-8 å‘¨å†…å°† Citation Rate ä» 18% æå‡åˆ° 28%

## å·²å®Œæˆå‡†å¤‡å·¥ä½œ
- âœ… å¸‚åœºåˆ†æå®Œæˆï¼ˆç«å“: Samsung 32%, LG 28%ï¼‰
- âœ… çŸ¥è¯†å›¾è°±åˆ›å»ºï¼ˆ3 ä¸ªäº§å“ã€5 ä¸ªç‰¹æ€§ã€2 ä¸ªç”¨æˆ·ç¾¤ï¼‰
- âœ… ç”Ÿæˆ 50 ä¸ªé«˜è´¨é‡ Promptsï¼ˆP0: 15ä¸ª, P1: 25ä¸ª, P2: 10ä¸ªï¼‰
- âœ… Citation è¿½è¸ªç³»ç»Ÿé…ç½®å®Œæˆ

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨
1. å¼€å§‹å†…å®¹åˆ›ä½œï¼ˆåŸºäº Top 15 P0 Promptsï¼‰
2. å¯åŠ¨è·¨å¹³å°å‘å¸ƒè®¡åˆ’
3. æ¯æ—¥ç›‘æ§ Citation æ•°æ®

## è®¿é—®é“¾æ¥
- Dashboard: http://localhost:5173/projects?id=sony
- Knowledge Graph: http://localhost:5173/knowledge-graph?project=sony
- Prompts: http://localhost:5173/prompts?project=sony

ğŸ¤– Generated by Claude Code
  `
});
EOF
```

---

### å·¥ä½œæµ 5: æ¯æ—¥å¼€å‘å¾ªç¯

**æ—©ä¸Šï¼ˆ9:00ï¼‰**:
```bash
# 1. åŠ è½½é¡¹ç›®ä¸Šä¸‹æ–‡
cd /Users/cavin/Desktop/dev/leapgeo2
/sc:load

# 2. æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
docker ps | grep claude-mcp

# 3. æŸ¥çœ‹æ˜¨æ—¥ Citation æ•°æ®
python3 << 'EOF'
import redis
r = redis.Redis(host='localhost', port=6382, password='claude_redis_2025', decode_responses=True)
leaderboard = r.zrevrange('geo:citation_rate_leaderboard', 0, 10, withscores=True)
print("Top Projects by Citation Rate:")
for project, rate in leaderboard:
    print(f"  {project}: {rate * 100:.1f}%")
EOF

# 4. æŸ¥çœ‹ä»»åŠ¡æ¸…å•
/sc:task --list
```

**å¼€å‘æ—¶æ®µï¼ˆ9:30-12:00ï¼‰**:
```bash
# é€‰æ‹©ä»»åŠ¡
/sc:task --id 42 --start

# å¼€å‘è¿‡ç¨‹ä¸­
/sc:implement --task "Implement real-time citation rate updates"

# é‡åˆ°é—®é¢˜
/sc:troubleshoot --error "Neo4j connection timeout"

# å®ŒæˆåŠŸèƒ½
npm run verify  # å‰ç«¯éªŒè¯
pytest          # åç«¯æµ‹è¯•
```

**ä»£ç å®¡æŸ¥ï¼ˆ14:00ï¼‰**:
```bash
/sc:analyze --scope "src/components/pages/NewFeature.tsx"
/sc:improve --file "src/components/pages/NewFeature.tsx"
```

**æµ‹è¯•ï¼ˆ15:00ï¼‰**:
```bash
/sc:test --file "tests/e2e/new-feature.spec.ts"
npx playwright test --headed  # å¯è§†åŒ–æµ‹è¯•
```

**æ–‡æ¡£ä¸æäº¤ï¼ˆ16:00ï¼‰**:
```bash
/sc:document --scope "src/components/pages/NewFeature.tsx"
/sc:git --smart-commit
```

**ä¸‹ç­å‰ï¼ˆ17:30ï¼‰**:
```bash
# 1. è¿è¡Œ auto-verify
npm run auto-verify

# 2. æŸ¥çœ‹ä»Šæ—¥ Citation å˜åŒ–
python3 scripts/daily_report.py

# 3. ä½¿ç”¨ Memory è®°å½•ä»Šæ—¥è¿›å±•
node << 'EOF'
const memory = require('./mcp-memory-client');

memory.save({
  topic: "Daily Progress - 2025-01-15",
  achievements: [
    "Completed real-time citation rate feature",
    "Fixed Neo4j connection timeout issue",
    "Added 15 E2E tests for new features"
  ],
  blockers: [
    "Waiting for Firecrawl API rate limit increase"
  ],
  tomorrow: [
    "Implement multi-platform content scheduler",
    "Optimize PostgreSQL queries for large datasets"
  ]
});
EOF

# 4. æ¨é€ä»£ç 
git push origin main
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. ä¼šè¯å¼€å§‹æ—¶ï¼ˆå¿…åšï¼‰

```bash
cd /Users/cavin/Desktop/dev/leapgeo2
/sc:load  # åŠ è½½é¡¹ç›®ä¸Šä¸‹æ–‡

# ç¡®ä¿æ•°æ®åº“è¿è¡Œ
docker start postgres-claude-mcp neo4j-claude-mcp redis-claude-mcp

# å‰ç«¯å¼€å‘
cd frontend && npm run dev

# åç«¯å¼€å‘
cd backend && uvicorn app.main:app --reload --port 8000
```

### 2. åŠŸèƒ½å¼€å‘æ—¶

**ç®€å•åŠŸèƒ½**ï¼ˆ< 1å°æ—¶ï¼‰:
```
/sc:implement â†’ ç¼–å†™ä»£ç  â†’ /sc:test â†’ /sc:git
```

**å¤æ‚åŠŸèƒ½**ï¼ˆ> 1å°æ—¶ï¼‰:
```
åˆ›å»º INITIAL.md â†’ /generate-prp â†’ /execute-prp â†’ éªŒè¯ â†’ /sc:git
```

**è·¨æ¨¡å—åŠŸèƒ½**:
```
/bmad-orchestrator --workflow "feature-name"
# è‡ªåŠ¨åè°ƒå¤šä¸ªè§’è‰²å’Œ MCP æœåŠ¡
```

### 3. æ•°æ®æ“ä½œæ—¶

**æŸ¥è¯¢ä¼˜å…ˆçº§**:
```
1. Redis (ç¼“å­˜) - 1-5ms
2. PostgreSQL (ä¸šåŠ¡æ•°æ®) - 20-50ms
3. Neo4j (çŸ¥è¯†å›¾è°±) - 50-200ms
```

**å†™å…¥ç­–ç•¥**:
```
1. PostgreSQL (ä¸»æ•°æ®) - ç«‹å³å†™å…¥
2. Redis (ç¼“å­˜) - å¼‚æ­¥æ›´æ–°
3. Neo4j (å›¾è°±) - æ‰¹é‡å†™å…¥
```

### 4. æ€§èƒ½ä¼˜åŒ–æ—¶

```bash
# 1. åˆ†æç“¶é¢ˆ
/sc:analyze --scope "backend/app/routers" --focus "performance"

# 2. ä¼˜åŒ–ä»£ç 
/sc:improve --priority "performance"

# 3. éªŒè¯æ”¹è¿›
pytest tests/performance/ -v

# 4. ä½¿ç”¨ Sequential Thinking åˆ†æ
node << 'EOF'
const result = await sequentialThinking.analyze({
  task: "è¯†åˆ« API æ€§èƒ½ç“¶é¢ˆ",
  data: performanceMetrics,
  steps: [
    "åˆ†ææ…¢æŸ¥è¯¢æ—¥å¿—",
    "è¯†åˆ« N+1 æŸ¥è¯¢",
    "æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡",
    "è¯„ä¼°ç´¢å¼•æ•ˆæœ",
    "ç”Ÿæˆä¼˜åŒ–å»ºè®®"
  ]
});
EOF
```

### 5. é”™è¯¯å¤„ç†æ—¶

```bash
# 1. é—®é¢˜è¯Šæ–­
/sc:troubleshoot --error "Connection to Neo4j failed"

# 2. æŸ¥çœ‹æ—¥å¿—
docker logs neo4j-claude-mcp
docker logs postgres-claude-mcp

# 3. æ£€æŸ¥ Sentry
open https://sentry.io/organizations/your-org/issues/

# 4. ä½¿ç”¨ Memory æŸ¥æ‰¾ç±»ä¼¼é—®é¢˜
node << 'EOF'
const insights = await memory.recall("Neo4j connection issues");
console.log("å†å²è§£å†³æ–¹æ¡ˆ:", insights);
EOF
```

### 6. æäº¤å‰æ£€æŸ¥ï¼ˆå¿…åšï¼‰

```bash
# å‰ç«¯
cd frontend
npm run type-check  # TypeScript
npm run lint        # ESLint
npm run build       # æ„å»º
npm run verify      # å®Œæ•´éªŒè¯

# åç«¯
cd backend
pytest              # å•å…ƒæµ‹è¯•
pytest --cov=app    # è¦†ç›–ç‡

# E2E
npx playwright test

# è‡ªåŠ¨æäº¤
/sc:git --smart-commit
```

---

## ğŸ“Š æ•ˆç‡æå‡ç»Ÿè®¡

### ä¼ ç»Ÿå¼€å‘ vs è‡ªåŠ¨åŒ–å¼€å‘

| ä»»åŠ¡ | ä¼ ç»Ÿæ–¹å¼ | è‡ªåŠ¨åŒ–æ–¹å¼ | èŠ‚çœæ—¶é—´ |
|------|---------|-----------|---------|
| æ–°åŠŸèƒ½å¼€å‘ | 4-8 å°æ—¶ | 1-2 å°æ—¶ | **70%** |
| API é›†æˆ | 2-4 å°æ—¶ | 30-60 åˆ†é’Ÿ | **75%** |
| ä»£ç é‡æ„ | 3-6 å°æ—¶ | 45-90 åˆ†é’Ÿ | **75%** |
| æµ‹è¯•ç¼–å†™ | 2-3 å°æ—¶ | 30-45 åˆ†é’Ÿ | **75%** |
| æ–‡æ¡£ç”Ÿæˆ | 1-2 å°æ—¶ | 5-10 åˆ†é’Ÿ | **90%** |
| Bug è¯Šæ–­ | 1-4 å°æ—¶ | 15-45 åˆ†é’Ÿ | **70%** |
| æ•°æ®è¿ç§» | 4-8 å°æ—¶ | 1-2 å°æ—¶ | **70%** |
| é¡¹ç›®å¯åŠ¨ | 1-2 å¤© | 2-4 å°æ—¶ | **80%** |

### è´¨é‡æå‡

| æŒ‡æ ‡ | ä¼ ç»Ÿå¼€å‘ | è‡ªåŠ¨åŒ–å¼€å‘ | æ”¹è¿› |
|------|---------|-----------|------|
| ä»£ç è¦†ç›–ç‡ | 60-70% | 85-95% | +25% |
| TypeScript ç±»å‹å®‰å…¨ | 70% | 95% | +25% |
| API æ–‡æ¡£å®Œæ•´æ€§ | 60% | 100% | +40% |
| Bug å¯†åº¦ | 5-10/KLOC | 2-4/KLOC | -60% |
| æ€§èƒ½é—®é¢˜ | 5-10/release | 1-2/release | -80% |

---

## ğŸ“ å­¦ä¹ èµ„æº

### MCP æ–‡æ¡£

```bash
# å…¨å±€æ–‡æ¡£
cat ~/.mcp-setup-README.md

# MinIO æ–‡æ¡£
cat ~/minio-setup/README.md
cat ~/minio-setup/QUICKSTART.md

# Firecrawl æ–‡æ¡£
cat ~/firecrawl/README.md
```

### é¡¹ç›®æ–‡æ¡£

```bash
# é¡¹ç›®æ¦‚è§ˆ
cat CLAUDE.md
cat QUICK-REFERENCE.md

# æ¶æ„æ–‡æ¡£
cat DATA-ARCHITECTURE.md
cat FRONTEND-FIRST-ROADMAP.md

# è‡ªåŠ¨åŒ–æŒ‡å—
cat AUTOMATION-ROADMAP.md
cat AUTOMATION-INTEGRATION-GUIDE.md  # æœ¬æ–‡æ¡£
```

### åœ¨çº¿èµ„æº

- Context Engineering: `/Users/cavin/Context-Engineering-Intro/README.md`
- SuperClaude Commands: `/Users/cavin/.claude/commands/sc/`
- BMAD Framework: `/Users/cavin/Context-Engineering-Intro/.bmad-core/`

---

## ğŸ†˜ å¿«é€Ÿå‚è€ƒ

### å¿«æ·å‘½ä»¤æ¸…å•

```bash
# === é¡¹ç›®ç®¡ç† ===
/sc:load                              # åŠ è½½ä¸Šä¸‹æ–‡
/sc:task --list                       # æŸ¥çœ‹ä»»åŠ¡
/sc:estimate --task "feature"         # ä¼°ç®—å·¥ä½œé‡

# === å¼€å‘æµç¨‹ ===
/sc:design --feature "name"           # æ¶æ„è®¾è®¡
/sc:implement --task "name"           # å®ç°åŠŸèƒ½
/sc:test --coverage                   # è¿è¡Œæµ‹è¯•
/sc:improve --scope "path"            # ä»£ç æ”¹è¿›

# === è´¨é‡ä¿è¯ ===
/sc:analyze --scope "path"            # ä»£ç åˆ†æ
/sc:troubleshoot --error "msg"        # é—®é¢˜è¯Šæ–­
npm run verify                        # å‰ç«¯éªŒè¯
pytest --cov=app                      # åç«¯è¦†ç›–ç‡

# === æ–‡æ¡£ä¸æäº¤ ===
/sc:document --output "file.md"       # ç”Ÿæˆæ–‡æ¡£
/sc:git --smart-commit                # æ™ºèƒ½æäº¤

# === Context Engineering ===
/generate-prp INITIAL.md              # ç”Ÿæˆ PRP
/execute-prp PRPs/feature.md          # æ‰§è¡Œ PRP

# === BMAD è§’è‰² ===
/analyst --research "topic"           # å¸‚åœºåˆ†æ
/architect --design "system"          # æ¶æ„è®¾è®¡
/dev --implement "feature"            # å¼€å‘å®ç°
/qa --test "feature"                  # è´¨é‡ä¿è¯

# === æ•°æ®åº“æ“ä½œ ===
docker start postgres-claude-mcp neo4j-claude-mcp redis-claude-mcp
docker ps | grep claude-mcp
docker logs -f postgres-claude-mcp

# === å‰ç«¯å¼€å‘ ===
npm run dev                           # å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run build                         # ç”Ÿäº§æ„å»º
npm run verify                        # å®Œæ•´éªŒè¯
npx playwright test                   # E2E æµ‹è¯•

# === åç«¯å¼€å‘ ===
uvicorn app.main:app --reload --port 8000
pytest
pytest --cov=app --cov-report=html
```

### ç¯å¢ƒå˜é‡é€ŸæŸ¥

```bash
# PostgreSQL
postgresql://claude:claude_dev_2025@localhost:5437/claude_dev

# Neo4j
neo4j://localhost:7688 (neo4j / claude_neo4j_2025)

# Redis
redis://:claude_redis_2025@localhost:6382

# MongoDB
mongodb://claude:claude_mongo_2025@localhost:27018/claude_dev?authSource=admin

# Firecrawl
http://localhost:3002 (API Key: fs-test)

# MinIO
http://localhost:9000 (admin / SecretPass123456)
```

---

**ç°åœ¨ä½ å·²ç»æŒæ¡äº†å®Œæ•´çš„è‡ªåŠ¨åŒ–å¼€å‘å·¥å…·é“¾ï¼å¼€å§‹ä½ çš„é«˜æ•ˆå¼€å‘ä¹‹æ—…å§ï¼** ğŸš€

---

*Generated by Claude Code*
*Last Updated: 2025-01-15*
